---
title: "Validation and Backend Checks"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Validation and Backend Checks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
library(blockjack)
```

This vignette shows how to validate `blockjack` in practice, including backend
selection and numerical equivalence checks.

## Backend Design

`blockjack` now supports two computational backends in `block_jackknife_fit()`
and `bjlm()`:

- `backend = "Rcpp"` (default): compiled backend for speed.
- `backend = "R"`: reference backend in pure R.

If `backend = "Rcpp"` is requested but compiled symbols are unavailable,
`blockjack` falls back to `backend = "R"` with a warning.

## 1. OLS Accuracy Check (default backend)

```{r}
set.seed(101)
n <- 20000
x1 <- rnorm(n)
x2 <- rnorm(n)
y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n)
d <- data.frame(y = y, x1 = x1, x2 = x2)

fit_bj <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200)  # default backend=Rcpp
fit_lm <- lm(y ~ x1 + x2, data = d)

coef_diff <- max(abs(coef(fit_bj) - coef(fit_lm)))
se_ols <- coef(summary(fit_lm))[, 2]
se_abs_diff <- max(abs(fit_bj$se - se_ols))
se_rel_diff <- max(abs(fit_bj$se - se_ols) / pmax(se_ols, 1e-12))

c(
  backend = fit_bj$backend,
  coef_max_diff = coef_diff,
  se_max_abs_diff = se_abs_diff,
  se_max_rel_diff = se_rel_diff
)
```

Expected:

- coefficients are effectively identical to `lm`.
- JK SE are close (not exactly equal) to classical model SE.

## 2. WLS Accuracy Check (default backend)

```{r}
set.seed(202)
n <- 20000
x1 <- rnorm(n)
x2 <- rnorm(n)
v <- exp(0.7 * x1)
w <- 1 / v
y <- 0.4 + 0.8 * x1 - 0.3 * x2 + rnorm(n, sd = sqrt(v))
d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)

fit_bj_w <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200)
fit_wls <- lm(y ~ x1 + x2, data = d, weights = w)

coef_table <- cbind(
  blockjack = coef(fit_bj_w),
  wls = coef(fit_wls),
  diff = coef(fit_bj_w) - coef(fit_wls)
)

se_wls <- coef(summary(fit_wls))[, 2]
se_table <- cbind(
  blockjack_jk_se = fit_bj_w$se,
  wls_se = se_wls,
  abs_diff = abs(fit_bj_w$se - se_wls),
  rel_diff = abs(fit_bj_w$se - se_wls) / pmax(se_wls, 1e-12)
)

round(coef_table, 10)
round(se_table, 10)
```

Expected:

- weighted coefficients match WLS coefficients very closely.
- JK and model-based WLS SE are close.

## 3. OLS and WLS Monte Carlo Ratio Checks (200 runs each)

The following checks mirror the cluster-style summary by computing quantiles of
`JK SE / model SE` over repeated simulations.

```{r}
ratio_quantiles <- function(ratio_mat) {
  round(apply(ratio_mat, 2, quantile, probs = c(0.05, 0.50, 0.95)), 4)
}

set.seed(910)
n <- 20000
R <- 200

# OLS
ratio_ols <- matrix(NA_real_, R, 3)
colnames(ratio_ols) <- c("(Intercept)", "x1", "x2")
for (i in seq_len(R)) {
  x1 <- rnorm(n); x2 <- rnorm(n)
  d <- data.frame(y = 0.5 - 0.2 * x1 + 0.1 * x2 + rnorm(n), x1 = x1, x2 = x2)
  fit_bj <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200)
  fit_lm <- lm(y ~ x1 + x2, data = d)
  ratio_ols[i, ] <- fit_bj$se / coef(summary(fit_lm))[, 2]
}

# WLS
ratio_wls <- matrix(NA_real_, R, 3)
colnames(ratio_wls) <- c("(Intercept)", "x1", "x2")
for (i in seq_len(R)) {
  x1 <- rnorm(n); x2 <- rnorm(n)
  v <- exp(0.7 * x1); w <- 1 / v
  y <- 0.4 + 0.8 * x1 - 0.3 * x2 + rnorm(n, sd = sqrt(v))
  d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)
  fit_bj <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200)
  fit_wls <- lm(y ~ x1 + x2, data = d, weights = w)
  ratio_wls[i, ] <- fit_bj$se / coef(summary(fit_wls))[, 2]
}

list(
  ols_jk_over_lm = ratio_quantiles(ratio_ols),
  wls_jk_over_wls = ratio_quantiles(ratio_wls)
)
```

Typical observed quantiles from this setup:

- OLS `JK/OLS_SE`:
  - `(Intercept)`: `0.9315, 1.0007, 1.0827`
  - `x1`: `0.9227, 1.0033, 1.0787`
  - `x2`: `0.9186, 1.0045, 1.0821`
- WLS `JK/WLS_SE`:
  - `(Intercept)`: `0.9069, 0.9948, 1.0753`
  - `x1`: `0.9117, 1.0012, 1.0884`
  - `x2`: `0.9188, 0.9963, 1.0734`

## 4. Cluster-Aware Jackknife vs `vcovCL`

When `cluster=` is supplied, clusters are not split across jackknife blocks.

```{r, message = FALSE}
if (!requireNamespace("sandwich", quietly = TRUE)) {
  stop("Please install 'sandwich' to run cluster validation.")
}

set.seed(303)
n <- 20000
cluster_size <- 10
n_clusters <- n / cluster_size
n_runs <- 100

ratio <- matrix(NA_real_, n_runs, 3)
colnames(ratio) <- c("(Intercept)", "x1", "x2")

for (r in seq_len(n_runs)) {
  cl <- rep(seq_len(n_clusters), each = cluster_size)
  g1 <- rep(rnorm(n_clusters), each = cluster_size)
  g2 <- rep(rnorm(n_clusters), each = cluster_size)
  x1 <- sqrt(0.8) * g1 + sqrt(0.2) * rnorm(n)
  x2 <- sqrt(0.8) * g2 + sqrt(0.2) * rnorm(n)
  u <- rep(rnorm(n_clusters, sd = 2), each = cluster_size)
  y <- 0.5 + 0.7 * x1 - 0.2 * x2 + u + rnorm(n)
  d <- data.frame(y = y, x1 = x1, x2 = x2, cl = cl)

  fit_bj <- bjlm(y ~ x1 + x2, data = d, cluster = "cl", n_blocks = 200)
  fit_lm <- lm(y ~ x1 + x2, data = d)
  se_cl <- sqrt(diag(sandwich::vcovCL(fit_lm, cluster = d$cl)))

  ratio[r, ] <- fit_bj$se / se_cl
}

round(apply(ratio, 2, quantile, probs = c(0.05, 0.50, 0.95)), 4)
```

Expected: JK/`vcovCL` ratios near 1 with simulation variability.

## 5. Strict Backend Equivalence (Rcpp vs R)

```{r}
set.seed(404)
n <- 12000
X <- cbind(1, matrix(rnorm(n * 2), n, 2))
y <- drop(X %*% c(0.5, -0.2, 0.1) + rnorm(n))

fit_r <- block_jackknife_fit(X, y, n_blocks = 100, backend = "R")
fit_cpp <- block_jackknife_fit(X, y, n_blocks = 100, backend = "Rcpp")

c(
  max_coef_diff = max(abs(fit_r$coefficients - fit_cpp$coefficients)),
  max_se_diff = max(abs(fit_r$se - fit_cpp$se)),
  max_cov_diff = max(abs(fit_r$cov - fit_cpp$cov))
)
```

Expected: very small differences (near floating-point tolerance).

## 6. Backend Timing Benchmark

The chunk below provides a small local benchmark comparing `backend = "Rcpp"`
against `backend = "R"` for OLS, WLS, and cluster/block-id scenarios.

```{r}
bench_median <- function(fun, reps = 4, iterations = 12) {
  t <- numeric(reps)
  for (i in seq_len(reps)) {
    gc(FALSE)
    tt <- system.time({
      for (j in seq_len(iterations)) fun()
    })
    t[i] <- unname(tt[["elapsed"]]) / iterations
  }
  median(t)
}

set.seed(505)
n <- 12000
x1 <- rnorm(n); x2 <- rnorm(n)
X <- cbind(1, x1, x2)
y <- drop(X %*% c(0.5, -0.2, 0.1) + rnorm(n))
v <- exp(0.5 * x1); w <- 1 / v
cl <- rep(seq_len(n / 10), each = 10)
block_id <- ((cl - 1L) %% 100L) + 1L

med_r_ols <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, backend = "R"))
med_c_ols <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, backend = "Rcpp"))

med_r_wls <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, weights = w, backend = "R"))
med_c_wls <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, weights = w, backend = "Rcpp"))

med_r_cl <- bench_median(function() block_jackknife_fit(X, y, block_id = block_id, backend = "R"))
med_c_cl <- bench_median(function() block_jackknife_fit(X, y, block_id = block_id, backend = "Rcpp"))

data.frame(
  scenario = c("OLS", "WLS", "Cluster"),
  median_R = c(med_r_ols, med_r_wls, med_r_cl),
  median_Rcpp = c(med_c_ols, med_c_wls, med_c_cl),
  speedup_Rcpp_vs_R = c(med_r_ols / med_c_ols, med_r_wls / med_c_wls, med_r_cl / med_c_cl)
)
```

Interpretation: speedups are machine- and workload-dependent, but `backend = "Rcpp"`
should typically be faster than the pure R backend.
