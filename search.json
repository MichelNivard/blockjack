[{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"backend-design","dir":"Articles","previous_headings":"","what":"Backend Design","title":"Validation and Backend Checks","text":"blockjack now supports two computational backends block_jackknife_fit() bjlm(): backend = \"Rcpp\" (default): compiled backend speed. backend = \"R\": reference backend pure R. backend = \"Rcpp\" requested compiled symbols unavailable, blockjack falls back backend = \"R\" warning.","code":""},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"ols-accuracy-check-default-backend","dir":"Articles","previous_headings":"","what":"1. OLS Accuracy Check (default backend)","title":"Validation and Backend Checks","text":"Expected: coefficients effectively identical lm. JK SE close (exactly equal) classical model SE.","code":"set.seed(101) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n) d <- data.frame(y = y, x1 = x1, x2 = x2)  fit_bj <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200)  # default backend=Rcpp fit_lm <- lm(y ~ x1 + x2, data = d)  coef_diff <- max(abs(coef(fit_bj) - coef(fit_lm))) se_ols <- coef(summary(fit_lm))[, 2] se_abs_diff <- max(abs(fit_bj$se - se_ols)) se_rel_diff <- max(abs(fit_bj$se - se_ols) / pmax(se_ols, 1e-12))  c(   backend = fit_bj$backend,   coef_max_diff = coef_diff,   se_max_abs_diff = se_abs_diff,   se_max_rel_diff = se_rel_diff ) #>                backend          coef_max_diff        se_max_abs_diff  #>                 \"Rcpp\" \"5.55111512312578e-16\" \"0.000592789382082578\"  #>        se_max_rel_diff  #>    \"0.084347206108753\""},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"wls-accuracy-check-default-backend","dir":"Articles","previous_headings":"","what":"2. WLS Accuracy Check (default backend)","title":"Validation and Backend Checks","text":"Expected: weighted coefficients match WLS coefficients closely. JK model-based WLS SE close.","code":"set.seed(202) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) v <- exp(0.7 * x1) w <- 1 / v y <- 0.4 + 0.8 * x1 - 0.3 * x2 + rnorm(n, sd = sqrt(v)) d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)  fit_bj_w <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200) fit_wls <- lm(y ~ x1 + x2, data = d, weights = w)  coef_table <- cbind(   blockjack = coef(fit_bj_w),   wls = coef(fit_wls),   diff = coef(fit_bj_w) - coef(fit_wls) )  se_wls <- coef(summary(fit_wls))[, 2] se_table <- cbind(   blockjack_jk_se = fit_bj_w$se,   wls_se = se_wls,   abs_diff = abs(fit_bj_w$se - se_wls),   rel_diff = abs(fit_bj_w$se - se_wls) / pmax(se_wls, 1e-12) )  round(coef_table, 10) #>              blockjack        wls diff #> (Intercept)  0.3972959  0.3972959    0 #> x1           0.8034756  0.8034756    0 #> x2          -0.3017081 -0.3017081    0 round(se_table, 10) #>             blockjack_jk_se      wls_se     abs_diff    rel_diff #> (Intercept)     0.007628293 0.007616547 0.0000117460 0.001542166 #> x1              0.006215225 0.006197613 0.0000176120 0.002841740 #> x2              0.005839611 0.006169317 0.0003297062 0.053442891"},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"ols-and-wls-monte-carlo-ratio-checks-200-runs-each","dir":"Articles","previous_headings":"","what":"3. OLS and WLS Monte Carlo Ratio Checks (200 runs each)","title":"Validation and Backend Checks","text":"following checks mirror cluster-style summary computing quantiles JK SE / model SE repeated simulations. Typical observed quantiles setup: (Intercept): 0.9315, 1.0007, 1.0827 x1: 0.9227, 1.0033, 1.0787 x2: 0.9186, 1.0045, 1.0821 (Intercept): 0.9069, 0.9948, 1.0753 x1: 0.9117, 1.0012, 1.0884 x2: 0.9188, 0.9963, 1.0734","code":"ratio_quantiles <- function(ratio_mat) {   round(apply(ratio_mat, 2, quantile, probs = c(0.05, 0.50, 0.95)), 4) }  set.seed(910) n <- 20000 R <- 200  # OLS ratio_ols <- matrix(NA_real_, R, 3) colnames(ratio_ols) <- c(\"(Intercept)\", \"x1\", \"x2\") for (i in seq_len(R)) {   x1 <- rnorm(n); x2 <- rnorm(n)   d <- data.frame(y = 0.5 - 0.2 * x1 + 0.1 * x2 + rnorm(n), x1 = x1, x2 = x2)   fit_bj <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200)   fit_lm <- lm(y ~ x1 + x2, data = d)   ratio_ols[i, ] <- fit_bj$se / coef(summary(fit_lm))[, 2] }  # WLS ratio_wls <- matrix(NA_real_, R, 3) colnames(ratio_wls) <- c(\"(Intercept)\", \"x1\", \"x2\") for (i in seq_len(R)) {   x1 <- rnorm(n); x2 <- rnorm(n)   v <- exp(0.7 * x1); w <- 1 / v   y <- 0.4 + 0.8 * x1 - 0.3 * x2 + rnorm(n, sd = sqrt(v))   d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)   fit_bj <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200)   fit_wls <- lm(y ~ x1 + x2, data = d, weights = w)   ratio_wls[i, ] <- fit_bj$se / coef(summary(fit_wls))[, 2] }  list(   ols_jk_over_lm = ratio_quantiles(ratio_ols),   wls_jk_over_wls = ratio_quantiles(ratio_wls) ) #> $ols_jk_over_lm #>     (Intercept)     x1     x2 #> 5%       0.9315 0.9227 0.9186 #> 50%      1.0007 1.0033 1.0045 #> 95%      1.0827 1.0787 1.0821 #>  #> $wls_jk_over_wls #>     (Intercept)     x1     x2 #> 5%       0.9069 0.9117 0.9188 #> 50%      0.9948 1.0012 0.9963 #> 95%      1.0753 1.0884 1.0734"},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"cluster-aware-jackknife-vs-vcovcl","dir":"Articles","previous_headings":"","what":"4. Cluster-Aware Jackknife vs vcovCL","title":"Validation and Backend Checks","text":"cluster= supplied, clusters split across jackknife blocks. Expected: JK/vcovCL ratios near 1 simulation variability.","code":"if (!requireNamespace(\"sandwich\", quietly = TRUE)) {   stop(\"Please install 'sandwich' to run cluster validation.\") }  set.seed(303) n <- 20000 cluster_size <- 10 n_clusters <- n / cluster_size n_runs <- 100  ratio <- matrix(NA_real_, n_runs, 3) colnames(ratio) <- c(\"(Intercept)\", \"x1\", \"x2\")  for (r in seq_len(n_runs)) {   cl <- rep(seq_len(n_clusters), each = cluster_size)   g1 <- rep(rnorm(n_clusters), each = cluster_size)   g2 <- rep(rnorm(n_clusters), each = cluster_size)   x1 <- sqrt(0.8) * g1 + sqrt(0.2) * rnorm(n)   x2 <- sqrt(0.8) * g2 + sqrt(0.2) * rnorm(n)   u <- rep(rnorm(n_clusters, sd = 2), each = cluster_size)   y <- 0.5 + 0.7 * x1 - 0.2 * x2 + u + rnorm(n)   d <- data.frame(y = y, x1 = x1, x2 = x2, cl = cl)    fit_bj <- bjlm(y ~ x1 + x2, data = d, cluster = \"cl\", n_blocks = 200)   fit_lm <- lm(y ~ x1 + x2, data = d)   se_cl <- sqrt(diag(sandwich::vcovCL(fit_lm, cluster = d$cl)))    ratio[r, ] <- fit_bj$se / se_cl }  round(apply(ratio, 2, quantile, probs = c(0.05, 0.50, 0.95)), 4) #>     (Intercept)     x1     x2 #> 5%       0.9142 0.9330 0.9200 #> 50%      1.0071 1.0103 1.0021 #> 95%      1.0811 1.0839 1.0874"},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"strict-backend-equivalence-rcpp-vs-r","dir":"Articles","previous_headings":"","what":"5. Strict Backend Equivalence (Rcpp vs R)","title":"Validation and Backend Checks","text":"Expected: small differences (near floating-point tolerance).","code":"set.seed(404) n <- 12000 X <- cbind(1, matrix(rnorm(n * 2), n, 2)) y <- drop(X %*% c(0.5, -0.2, 0.1) + rnorm(n))  fit_r <- block_jackknife_fit(X, y, n_blocks = 100, backend = \"R\") fit_cpp <- block_jackknife_fit(X, y, n_blocks = 100, backend = \"Rcpp\")  c(   max_coef_diff = max(abs(fit_r$coefficients - fit_cpp$coefficients)),   max_se_diff = max(abs(fit_r$se - fit_cpp$se)),   max_cov_diff = max(abs(fit_r$cov - fit_cpp$cov)) ) #> max_coef_diff   max_se_diff  max_cov_diff  #>  2.775558e-17  4.857226e-17  8.944668e-19"},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"backend-timing-benchmark","dir":"Articles","previous_headings":"","what":"6. Backend Timing Benchmark","title":"Validation and Backend Checks","text":"chunk provides small local benchmark comparing backend = \"Rcpp\" backend = \"R\" OLS, WLS, cluster/block-id scenarios. Interpretation: speedups machine- workload-dependent, backend = \"Rcpp\" typically faster pure R backend.","code":"bench_median <- function(fun, reps = 4, iterations = 12) {   t <- numeric(reps)   for (i in seq_len(reps)) {     gc(FALSE)     tt <- system.time({       for (j in seq_len(iterations)) fun()     })     t[i] <- unname(tt[[\"elapsed\"]]) / iterations   }   median(t) }  set.seed(505) n <- 12000 x1 <- rnorm(n); x2 <- rnorm(n) X <- cbind(1, x1, x2) y <- drop(X %*% c(0.5, -0.2, 0.1) + rnorm(n)) v <- exp(0.5 * x1); w <- 1 / v cl <- rep(seq_len(n / 10), each = 10) block_id <- ((cl - 1L) %% 100L) + 1L  med_r_ols <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, backend = \"R\")) med_c_ols <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, backend = \"Rcpp\"))  med_r_wls <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, weights = w, backend = \"R\")) med_c_wls <- bench_median(function() block_jackknife_fit(X, y, n_blocks = 100, weights = w, backend = \"Rcpp\"))  med_r_cl <- bench_median(function() block_jackknife_fit(X, y, block_id = block_id, backend = \"R\")) med_c_cl <- bench_median(function() block_jackknife_fit(X, y, block_id = block_id, backend = \"Rcpp\"))  data.frame(   scenario = c(\"OLS\", \"WLS\", \"Cluster\"),   median_R = c(med_r_ols, med_r_wls, med_r_cl),   median_Rcpp = c(med_c_ols, med_c_wls, med_c_cl),   speedup_Rcpp_vs_R = c(med_r_ols / med_c_ols, med_r_wls / med_c_wls, med_r_cl / med_c_cl) ) #>   scenario    median_R  median_Rcpp speedup_Rcpp_vs_R #> 1      OLS 0.002708333 0.0005000000          5.416667 #> 2      WLS 0.002708333 0.0004166667          6.500000 #> 3  Cluster 0.003000000 0.0006666667          4.500000"},{"path":"https://michelnivard.github.io/blockjack/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michel Nivard. Author, maintainer.","code":""},{"path":"https://michelnivard.github.io/blockjack/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Nivard M (2026). blockjack: Fast Block Jackknife Linear Regression. R package version 0.1.0, https://github.com/MichelNivard/blockjack.","code":"@Manual{,   title = {blockjack: Fast Block Jackknife for Linear Regression},   author = {Michel Nivard},   year = {2026},   note = {R package version 0.1.0},   url = {https://github.com/MichelNivard/blockjack}, }"},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"blockjack","dir":"","previous_headings":"","what":"blockjack","title":"blockjack","text":"Fast block jackknife standard errors linear regression.","code":""},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"what-it-does","dir":"","previous_headings":"","what":"What It Does","title":"blockjack","text":"blockjack computes linear-model coefficients block jackknife standard errors efficiently : Splitting rows blocks. Precomputing block-wise X'X X'y. Reusing crossproducts leave-one-block-fits. avoids refitting model scratch block much faster naive jackknife loops n_blocks large.","code":""},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"method-source","dir":"","previous_headings":"","what":"Method Source","title":"blockjack","text":"computational trick follows LD Score regression jackknife approach: Bulik-Sullivan, B., Loh, PR., Finucane, H. et al.Â LD Score regression distinguishes confounding polygenicity genome-wide association studies. Nat Genet 47, 291-295 (2015). https://doi.org/10.1038/ng.3211","code":""},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"install-locally","dir":"","previous_headings":"","what":"Install locally","title":"blockjack","text":"","code":"# install from GitHub if (!requireNamespace(\"remotes\", quietly = TRUE)) {   install.packages(\"remotes\") } remotes::install_github(\"MichelNivard/blockjack\") # or install from a local checkout (from package root) install.packages(\".\", repos = NULL, type = \"source\")"},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"blockjack","text":"OLS example: WLS example: Cluster-robust block jackknife example: Cluster notes: cluster supplied, bjlm() assigns whole clusters jackknife blocks (cluster split). warns n_clusters < n_blocks automatically reduces blocks n_clusters. warns largest cluster exceeds n / n_blocks. Validation summary (100 simulations, N=20000, cluster size 10, strong within-cluster correlation): Ratio JK SE / vcovCL SE quantiles (5%, 50%, 95%) (Intercept): 0.9398, 0.9955, 1.0763 x1: 0.9191, 1.0007, 1.0657 x2: 0.9174, 0.9966, 1.0825 setup, vcovCL SEs much larger OLS SEs (median vcovCL / OLS around 2.59 slopes), non-trivial clustered setting. Example output (OLS):","code":"library(blockjack)  set.seed(1) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n) d <- data.frame(y = y, x1 = x1, x2 = x2)  fit <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200) summary(fit) set.seed(2) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) v <- exp(0.7 * x1) w <- 1 / v y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n, sd = sqrt(v)) d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)  fit_wls <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200) summary(fit_wls) set.seed(3) n <- 20000 cluster_size <- 10 n_clusters <- n / cluster_size cl <- rep(seq_len(n_clusters), each = cluster_size)  g1 <- rep(rnorm(n_clusters), each = cluster_size) g2 <- rep(rnorm(n_clusters), each = cluster_size) x1 <- sqrt(0.8) * g1 + sqrt(0.2) * rnorm(n) x2 <- sqrt(0.8) * g2 + sqrt(0.2) * rnorm(n) u <- rep(rnorm(n_clusters, sd = 2), each = cluster_size) y <- 0.5 + 0.7 * x1 - 0.2 * x2 + u + rnorm(n) d <- data.frame(y = y, x1 = x1, x2 = x2, cl = cl)  # clusters are kept intact when forming jackknife blocks fit_cl <- bjlm(y ~ x1 + x2, data = d, cluster = \"cl\", n_blocks = 200) summary(fit_cl) Call: bjlm(formula = y ~ x1 + x2, data = d, n_blocks = 200)  Coefficients:              Estimate Jackknife SE z value Pr(>|z|) (Intercept)  0.493175     0.006641   74.26   <2e-16 *** x1           0.686438     0.007263   94.51   <2e-16 *** x2          -0.196584     0.007320  -26.86   <2e-16 *** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Residual standard error: 1.0071 on 19997 degrees of freedom Jackknife blocks: 200"}]
