[{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"ols-coefficients-match-lm-se-are-close","dir":"Articles","previous_headings":"","what":"1. OLS: coefficients match lm, SE are close","title":"Validation Checks","text":"Expected: coefficient difference near machine precision; SE differences small.","code":"set.seed(101) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n) d <- data.frame(y = y, x1 = x1, x2 = x2)  fit_bj <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200) fit_lm <- lm(y ~ x1 + x2, data = d)  coef_diff <- max(abs(coef(fit_bj) - coef(fit_lm))) se_ols <- coef(summary(fit_lm))[, 2] se_abs_diff <- max(abs(fit_bj$se - se_ols)) se_rel_diff <- max(abs(fit_bj$se - se_ols) / pmax(se_ols, 1e-12))  c(coef_max_diff = coef_diff,   se_max_abs_diff = se_abs_diff,   se_max_rel_diff = se_rel_diff) #>   coef_max_diff se_max_abs_diff se_max_rel_diff  #>    4.440892e-16    5.927894e-04    8.434721e-02"},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"wls-weighted-coefficients-match-lm----weights","dir":"Articles","previous_headings":"","what":"2. WLS: weighted coefficients match lm(..., weights=)","title":"Validation Checks","text":"Expected: coefficients match lm closely; JK SE WLS model SE close, identical.","code":"set.seed(202) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) v <- exp(0.7 * x1) w <- 1 / v y <- 0.4 + 0.8 * x1 - 0.3 * x2 + rnorm(n, sd = sqrt(v)) d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)  fit_bj_w <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200) fit_wls <- lm(y ~ x1 + x2, data = d, weights = w)  coef_table <- cbind(blockjack = coef(fit_bj_w),                     wls = coef(fit_wls),                     diff = coef(fit_bj_w) - coef(fit_wls))  se_wls <- coef(summary(fit_wls))[, 2] se_table <- cbind(blockjack_jk_se = fit_bj_w$se,                   wls_se = se_wls,                   abs_diff = abs(fit_bj_w$se - se_wls),                   rel_diff = abs(fit_bj_w$se - se_wls) / pmax(se_wls, 1e-12))  round(coef_table, 10) #>              blockjack        wls diff #> (Intercept)  0.3972959  0.3972959    0 #> x1           0.8034756  0.8034756    0 #> x2          -0.3017081 -0.3017081    0 round(se_table, 10) #>             blockjack_jk_se      wls_se     abs_diff    rel_diff #> (Intercept)     0.007628293 0.007616547 0.0000117460 0.001542166 #> x1              0.006215225 0.006197613 0.0000176120 0.002841740 #> x2              0.005839611 0.006169317 0.0003297062 0.053442891"},{"path":"https://michelnivard.github.io/blockjack/articles/validation.html","id":"cluster-aware-jk-compare-against-sandwichvcovcl","dir":"Articles","previous_headings":"","what":"3. Cluster-aware JK: compare against sandwich::vcovCL","title":"Validation Checks","text":"cluster= provided, bjlm() keeps clusters intact forming jackknife blocks. Expected: ratios near 1 (sampling variability), showing cluster-aware JK SE tracks vcovCL setting.","code":"if (!requireNamespace(\"sandwich\", quietly = TRUE)) {   stop(\"Please install 'sandwich' to run cluster validation.\") }  set.seed(303) n <- 20000 cluster_size <- 10 n_clusters <- n / cluster_size n_runs <- 100  ratio <- matrix(NA_real_, n_runs, 3) colnames(ratio) <- c(\"(Intercept)\", \"x1\", \"x2\")  for (r in seq_len(n_runs)) {   cl <- rep(seq_len(n_clusters), each = cluster_size)   g1 <- rep(rnorm(n_clusters), each = cluster_size)   g2 <- rep(rnorm(n_clusters), each = cluster_size)   x1 <- sqrt(0.8) * g1 + sqrt(0.2) * rnorm(n)   x2 <- sqrt(0.8) * g2 + sqrt(0.2) * rnorm(n)   u <- rep(rnorm(n_clusters, sd = 2), each = cluster_size)   y <- 0.5 + 0.7 * x1 - 0.2 * x2 + u + rnorm(n)   d <- data.frame(y = y, x1 = x1, x2 = x2, cl = cl)    fit_bj <- bjlm(y ~ x1 + x2, data = d, cluster = \"cl\", n_blocks = 200)   fit_lm <- lm(y ~ x1 + x2, data = d)   se_cl <- sqrt(diag(sandwich::vcovCL(fit_lm, cluster = d$cl)))    ratio[r, ] <- fit_bj$se / se_cl }  round(apply(ratio, 2, quantile, probs = c(0.05, 0.50, 0.95)), 4) #>     (Intercept)     x1     x2 #> 5%       0.9142 0.9330 0.9200 #> 50%      1.0071 1.0103 1.0021 #> 95%      1.0811 1.0839 1.0874"},{"path":"https://michelnivard.github.io/blockjack/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Michel Nivard. Author, maintainer.","code":""},{"path":"https://michelnivard.github.io/blockjack/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Nivard M (2026). blockjack: Fast Block Jackknife Linear Regression. R package version 0.1.0, https://github.com/MichelNivard/blockjack.","code":"@Manual{,   title = {blockjack: Fast Block Jackknife for Linear Regression},   author = {Michel Nivard},   year = {2026},   note = {R package version 0.1.0},   url = {https://github.com/MichelNivard/blockjack}, }"},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"blockjack","dir":"","previous_headings":"","what":"blockjack","title":"blockjack","text":"Fast block jackknife standard errors linear regression.","code":""},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"what-it-does","dir":"","previous_headings":"","what":"What It Does","title":"blockjack","text":"blockjack computes linear-model coefficients block jackknife standard errors efficiently : Splitting rows blocks. Precomputing block-wise X'X X'y. Reusing crossproducts leave-one-block-fits. avoids refitting model scratch block much faster naive jackknife loops n_blocks large.","code":""},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"method-source","dir":"","previous_headings":"","what":"Method Source","title":"blockjack","text":"computational trick follows LD Score regression jackknife approach: Bulik-Sullivan, B., Loh, PR., Finucane, H. et al.Â LD Score regression distinguishes confounding polygenicity genome-wide association studies. Nat Genet 47, 291-295 (2015). https://doi.org/10.1038/ng.3211","code":""},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"install-locally","dir":"","previous_headings":"","what":"Install locally","title":"blockjack","text":"","code":"# install from GitHub if (!requireNamespace(\"remotes\", quietly = TRUE)) {   install.packages(\"remotes\") } remotes::install_github(\"MichelNivard/blockjack\") # or install from a local checkout (from package root) install.packages(\".\", repos = NULL, type = \"source\")"},{"path":"https://michelnivard.github.io/blockjack/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"blockjack","text":"OLS example: WLS example: Cluster-robust block jackknife example: Cluster notes: cluster supplied, bjlm() assigns whole clusters jackknife blocks (cluster split). warns n_clusters < n_blocks automatically reduces blocks n_clusters. warns largest cluster exceeds n / n_blocks. Validation summary (100 simulations, N=20000, cluster size 10, strong within-cluster correlation): Ratio JK SE / vcovCL SE quantiles (5%, 50%, 95%) (Intercept): 0.9398, 0.9955, 1.0763 x1: 0.9191, 1.0007, 1.0657 x2: 0.9174, 0.9966, 1.0825 setup, vcovCL SEs much larger OLS SEs (median vcovCL / OLS around 2.59 slopes), non-trivial clustered setting. Example output (OLS):","code":"library(blockjack)  set.seed(1) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n) d <- data.frame(y = y, x1 = x1, x2 = x2)  fit <- bjlm(y ~ x1 + x2, data = d, n_blocks = 200) summary(fit) set.seed(2) n <- 20000 x1 <- rnorm(n) x2 <- rnorm(n) v <- exp(0.7 * x1) w <- 1 / v y <- 0.5 + 0.7 * x1 - 0.2 * x2 + rnorm(n, sd = sqrt(v)) d <- data.frame(y = y, x1 = x1, x2 = x2, w = w)  fit_wls <- bjlm(y ~ x1 + x2, data = d, weights = w, n_blocks = 200) summary(fit_wls) set.seed(3) n <- 20000 cluster_size <- 10 n_clusters <- n / cluster_size cl <- rep(seq_len(n_clusters), each = cluster_size)  g1 <- rep(rnorm(n_clusters), each = cluster_size) g2 <- rep(rnorm(n_clusters), each = cluster_size) x1 <- sqrt(0.8) * g1 + sqrt(0.2) * rnorm(n) x2 <- sqrt(0.8) * g2 + sqrt(0.2) * rnorm(n) u <- rep(rnorm(n_clusters, sd = 2), each = cluster_size) y <- 0.5 + 0.7 * x1 - 0.2 * x2 + u + rnorm(n) d <- data.frame(y = y, x1 = x1, x2 = x2, cl = cl)  # clusters are kept intact when forming jackknife blocks fit_cl <- bjlm(y ~ x1 + x2, data = d, cluster = \"cl\", n_blocks = 200) summary(fit_cl) Call: bjlm(formula = y ~ x1 + x2, data = d, n_blocks = 200)  Coefficients:              Estimate Jackknife SE z value Pr(>|z|) (Intercept)  0.493175     0.006641   74.26   <2e-16 *** x1           0.686438     0.007263   94.51   <2e-16 *** x2          -0.196584     0.007320  -26.86   <2e-16 *** --- Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1  Residual standard error: 1.0071 on 19997 degrees of freedom Jackknife blocks: 200"}]
